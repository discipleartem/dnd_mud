#!/usr/bin/env python3
"""–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞."""

from pathlib import Path
from tempfile import NamedTemporaryFile
from typing import Any
from unittest.mock import patch

import pytest
import yaml

from src.services.language_service import LanguageService
from src.ui.entities.character import Character
from src.ui.entities.race import RaceLoader
from src.ui.services.language_display_service import LanguageDisplayService
from src.ui.services.race_display_service import RaceDisplayService


@pytest.mark.integration
class TestRaceLanguageIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è —Ä–∞—Å –∏ —è–∑—ã–∫–æ–≤."""

    def create_complete_test_data(self) -> dict[str, Any]:
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å –∏ —è–∑—ã–∫–æ–≤."""
        return {
            "races": {
                "human": {
                    "name": "–ß–µ–ª–æ–≤–µ–∫",
                    "description": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ä–∞—Å–∞",
                    "ability_bonuses": {
                        "strength": 1,
                        "dexterity": 1,
                        "constitution": 1,
                        "intelligence": 1,
                        "wisdom": 1,
                        "charisma": 1
                    },
                    "ability_bonuses_description": "+1 –∫–æ –≤—Å–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º",
                    "size": "medium",
                    "speed": 30,
                    "age": {"adult": 18, "max": 100},
                    "languages": ["common"],
                    "features": [
                        {
                            "name": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ",
                            "description": "–í—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ",
                            "mechanics": {"type": "skill_bonus", "count": 1}
                        }
                    ],
                    "subraces": {
                        "variant": {
                            "name": "–í–∞—Ä–∏–∞–Ω—Ç–Ω—ã–π —á–µ–ª–æ–≤–µ–∫",
                            "description": "–ß–µ–ª–æ–≤–µ–∫ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –Ω–∞–≤—ã–∫–∞–º–∏",
                            "ability_bonuses": {"strength": 1, "dexterity": 1},
                            "ability_bonuses_description": "+2 –∫ –¥–≤—É–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º",
                            "inherit_base_abilities": False
                        }
                    },
                    "allow_base_race_choice": True
                },
                "elf": {
                    "name": "–≠–ª—å—Ñ",
                    "description": "–ò–∑—è—â–Ω–æ–µ –¥–æ–ª–≥–æ–∂–∏–≤—É—â–µ–µ —Å—É—â–µ—Å—Ç–≤–æ",
                    "ability_bonuses": {"dexterity": 2},
                    "ability_bonuses_description": "+2 –∫ –õ–æ–≤–∫–æ—Å—Ç–∏",
                    "size": "medium",
                    "speed": 30,
                    "age": {"adult": 100, "max": 750},
                    "languages": ["elvish", "common"],
                    "features": [
                        {
                            "name": "–¢–µ–º–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ",
                            "description": (
                                "–í—ã –º–æ–∂–µ—Ç–µ –≤–∏–¥–µ—Ç—å –≤ —É—Å–ª–æ–≤–∏—è—Ö "
                                "—Å–ª–∞–±–æ–≥–æ –æ—Å–≤–µ—â–µ–Ω–∏—è"
                            ),
                            "mechanics": {"type": "darkvision", "range": 60}
                        }
                    ],
                    "subraces": {
                        "high_elf": {
                            "name": "–í—ã—Å—à–∏–π —ç–ª—å—Ñ",
                            "description": "–ú–∞–≥–∏—á–µ—Å–∫–∏ –æ–¥–∞—Ä–µ–Ω–Ω—ã–π —ç–ª—å—Ñ",
                            "ability_bonuses": {"intelligence": 1},
                            "ability_bonuses_description": "+1 –∫ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É",
                            "languages": ["elvish"],
                            "features": [
                                {
                                    "name": "–ó–∞–∫–ª–∏–Ω–∞–Ω–∏–µ",
                                    "description": "–í—ã –∑–Ω–∞–µ—Ç–µ –æ–¥–Ω–æ –∫–∞–Ωtrip",
                                    "mechanics": {"type": "cantrip", "count": 1}
                                }
                            ],
                            "inherit_base_abilities": True
                        }
                    },
                    "allow_base_race_choice": False
                }
            },
            "language_metadata": {
                "types": {
                    "standard": "Standard",
                    "exotic": "Exotic"
                },
                "difficulties": {
                    "easy": "Easy",
                    "medium": "Medium",
                    "hard": "Hard"
                }
            },
            "languages": {
                "common": {
                    "code": "common",
                    "type": "standard",
                    "difficulty": "easy",
                    "localization_keys": {"name": "language.common.name"},
                    "mechanics": {"is_default": True, "learnable_by_all": True},
                    "fallback_data": {"name": "Common"}
                },
                "elvish": {
                    "code": "elvish",
                    "type": "standard",
                    "difficulty": "medium",
                    "localization_keys": {"name": "language.elvish.name"},
                    "mechanics": {"learnable_by": ["elf", "half_elf"]},
                    "fallback_data": {"name": "Elvish"}
                }
            }
        }

    def test_complete_race_language_workflow(self) -> None:
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å —Ä–∞—Å–∞–º–∏ –∏ —è–∑—ã–∫–∞–º–∏."""
        test_data = self.create_complete_test_data()

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as races_file:
            yaml.dump({"races": test_data["races"]}, races_file)
            races_file.flush()

            with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as languages_file:
                yaml.dump(
                    {
                        "language_metadata": test_data["language_metadata"],
                        "languages": test_data["languages"]
                    },
                    languages_file
                )
                languages_file.flush()

                try:
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
                    race_loader = RaceLoader(Path(races_file.name))
                    language_service = LanguageService(Path(languages_file.name))

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞—Å—ã
                    races = race_loader.load_races()
                    assert len(races) == 2
                    assert "human" in races
                    assert "elf" in races

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —è–∑—ã–∫–∏
                    languages = language_service.get_all_languages()
                    assert len(languages) == 2
                    assert "common" in languages
                    assert "elvish" in languages

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Ä–∞—Å –∏ —è–∑—ã–∫–æ–≤
                    human = races["human"]
                    elf = races["elf"]

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–∑—ã–∫–∏ —á–µ–ª–æ–≤–µ–∫–∞
                    assert human.languages == ["common"]
                    common_lang = language_service.get_language_by_code("common")
                    assert common_lang is not None

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–∑—ã–∫–∏ —ç–ª—å—Ñ–∞
                    assert elf.languages == ["elvish", "common"]
                    elvish_lang = language_service.get_language_by_code("elvish")
                    assert elvish_lang is not None

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —è–∑—ã–∫–æ–≤ –¥–ª—è —Ä–∞—Å
                    human_available = language_service.get_available_languages_for_race("human")
                    elf_available = language_service.get_available_languages_for_race("elf")

                    # –ß–µ–ª–æ–≤–µ–∫ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –¥–æ—Å—Ç—É–ø –∫ common (learnable_by_all=True)
                    assert common_lang in human_available

                    # –≠–ª—å—Ñ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –¥–æ—Å—Ç—É–ø –∫ elvish (learnable_by=["elf"]) –∏ common
                    assert elvish_lang in elf_available
                    assert common_lang in elf_available

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥—Ä–∞—Å—ã
                    human_variant = human.subraces["variant"]
                    elf_high = elf.subraces["high_elf"]

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–æ–Ω—É—Å—ã —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π
                    human_bonuses = human.get_effective_ability_bonuses(human_variant)
                    assert human_bonuses == {"strength": 1, "dexterity": 1}

                    elf_bonuses = elf.get_effective_ability_bonuses(elf_high)
                    assert elf_bonuses == {"dexterity": 2, "intelligence": 1}

                finally:
                    # –û—á–∏—Å—Ç–∫–∞
                    Path(races_file.name).unlink()
                    Path(languages_file.name).unlink()

    @patch('src.ui.entities.race.t')
    @patch('src.ui.services.language_display_service.t')
    def test_display_services_integration(self, mock_lang_t, mock_race_t) -> None:
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        test_data = self.create_complete_test_data()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–∫–æ–≤
        mock_lang_t.side_effect = lambda key: {
            "language.common.name": "–û–±—â–∏–π",
            "language.elvish.name": "–≠–ª—å—Ñ–∏–π—Å–∫–∏–π",
            "language.types.standard": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π",
            "language.difficulties.easy": "–õ–µ–≥–∫–∞—è",
            "language.difficulties.medium": "–°—Ä–µ–¥–Ω—è—è"
        }.get(key, key)

        mock_race_t.side_effect = lambda key: {
            "new_game.details_section.features_label": "–ß–µ—Ä—Ç—ã:",
            "new_game.details_section.abilities_label": "–ë–æ–Ω—É—Å—ã:"
        }.get(key, key)

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as races_file:
            yaml.dump({"races": test_data["races"]}, races_file)
            races_file.flush()

            with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as languages_file:
                yaml.dump(
                    {
                        "language_metadata": test_data["language_metadata"],
                        "languages": test_data["languages"]
                    },
                    languages_file
                )
                languages_file.flush()

                try:
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
                    race_loader = RaceLoader(Path(races_file.name))
                    language_service = LanguageService(Path(languages_file.name))

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    races = race_loader.load_races()
                    languages = language_service.get_all_languages()

                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤
                    common_lang = languages["common"]
                    elvish_lang = languages["elvish"]

                    common_name = LanguageDisplayService.get_language_name(common_lang)
                    elvish_name = LanguageDisplayService.get_language_name(elvish_lang)

                    assert common_name == "–û–±—â–∏–π"
                    assert elvish_name == "–≠–ª—å—Ñ–∏–π—Å–∫–∏–π"

                    common_type = LanguageDisplayService.get_language_type_name(common_lang)
                    elvish_difficulty = LanguageDisplayService.get_language_difficulty_name(elvish_lang)

                    assert common_type == "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π"
                    assert elvish_difficulty == "–°—Ä–µ–¥–Ω—è—è"

                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞—Å
                    elf = races["elf"]

                    with patch('builtins.print') as mock_print:
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —á–µ—Ä—Ç—ã
                        RaceDisplayService.display_features_with_emoji(elf.features)

                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –±–æ–Ω—É—Å—ã
                        RaceDisplayService.display_abilities_description(elf.ability_bonuses_description)

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–∑–æ–≤—ã print
                        print_calls = [str(call) for call in mock_print.call_args_list]

                        # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
                        print(f"DEBUG: Print calls: {print_calls}")

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä—Ç—ã (–±–æ–ª–µ–µ –≥–∏–±–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
                        features_found = any("–¢–µ–º–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ" in call for call in print_calls)
                        assert features_found, f"Expected '–¢–µ–º–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ' in print calls, got: {print_calls}"

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–º–æ–¥–∑–∏ –¥–ª—è —á–µ—Ä—Ç—ã
                        emoji_found = any("üåô" in call for call in print_calls)
                        assert emoji_found, f"Expected 'üåô' emoji in print calls, got: {print_calls}"

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–æ–Ω—É—Å—ã
                        bonuses_found = any("+2 –∫ –õ–æ–≤–∫–æ—Å—Ç–∏" in call for call in print_calls)
                        assert bonuses_found, f"Expected '+2 –∫ –õ–æ–≤–∫–æ—Å—Ç–∏' in print calls, got: {print_calls}"

                finally:
                    # –û—á–∏—Å—Ç–∫–∞
                    Path(races_file.name).unlink()
                    Path(languages_file.name).unlink()


@pytest.mark.integration
class TestCharacterCreationIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞."""

    def test_complete_character_creation(self) -> None:
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞."""
        test_data = {
            "races": {
                "human": {
                    "name": "–ß–µ–ª–æ–≤–µ–∫",
                    "description": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ä–∞—Å–∞",
                    "ability_bonuses": {"strength": 1, "dexterity": 1},
                    "ability_bonuses_description": "+1 –∫ –°–∏–ª–µ –∏ –õ–æ–≤–∫–æ—Å—Ç–∏",
                    "size": "medium",
                    "speed": 30,
                    "languages": ["common"],
                    "features": [
                        {
                            "name": "–ú–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ",
                            "description": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ",
                            "mechanics": {"type": "proficiency"}
                        }
                    ],
                    "subraces": {}
                }
            },
            "language_metadata": {"types": {}, "difficulties": {}},
            "languages": {
                "common": {
                    "code": "common",
                    "type": "standard",
                    "difficulty": "easy",
                    "localization_keys": {},
                    "mechanics": {"learnable_by_all": True},
                    "fallback_data": {"name": "Common"}
                }
            }
        }

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as races_file:
            yaml.dump({"races": test_data["races"]}, races_file)
            races_file.flush()

            with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as languages_file:
                yaml.dump(
                    {
                        "language_metadata": test_data["language_metadata"],
                        "languages": test_data["languages"]
                    },
                    languages_file
                )
                languages_file.flush()

                try:
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
                    race_loader = RaceLoader(Path(races_file.name))
                    language_service = LanguageService(Path(languages_file.name))

                    # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
                    character = Character(name="–¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂")

                    # –í—ã–±–∏—Ä–∞–µ–º —Ä–∞—Å—É
                    races = race_loader.load_races()
                    human_race = races["human"]
                    character.race = human_race

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
                    assert character.name == "–¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂"
                    assert character.race is human_race
                    assert character.size == human_race.size

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–æ–Ω—É—Å—ã –æ—Ç —Ä–∞—Å—ã
                    effective_bonuses = human_race.get_effective_ability_bonuses()
                    assert effective_bonuses == {"strength": 1, "dexterity": 1}

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–∑—ã–∫–∏ —Ä–∞—Å—ã
                    assert human_race.languages == ["common"]
                    common_lang = language_service.get_language_by_code("common")
                    assert common_lang is not None

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —è–∑—ã–∫–∏ –¥–ª—è —Ä–∞—Å—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
                    available_languages = language_service.get_available_languages_for_race("human")
                    assert common_lang in available_languages

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä—Ç—ã —Ä–∞—Å—ã
                    assert len(human_race.features) == 1
                    feature = human_race.features[0]
                    assert feature.name == "–ú–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ"
                    assert feature.description == "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ"

                finally:
                    # –û—á–∏—Å—Ç–∫–∞
                    Path(races_file.name).unlink()
                    Path(languages_file.name).unlink()


@pytest.mark.integration
@pytest.mark.slow
class TestPerformanceIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""

    def test_large_dataset_loading(self) -> None:
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö."""
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        large_races_data: dict[str, Any] = {"races": {}}
        large_languages_data: dict[str, Any] = {
            "language_metadata": {"types": {}, "difficulties": {}},
            "languages": {}
        }

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–Ω–æ–≥–æ —Ä–∞—Å
        for i in range(100):
            race_id = f"race_{i}"
            large_races_data["races"][race_id] = {
                "name": f"–†–∞—Å–∞ {i}",
                "description": f"–û–ø–∏—Å–∞–Ω–∏–µ —Ä–∞—Å—ã {i}",
                "ability_bonuses": {"strength": i % 3, "dexterity": i % 2},
                "size": "medium",
                "speed": 30,
                "languages": [f"lang_{i % 10}"],
                "features": [
                    {
                        "name": f"–ß–µ—Ä—Ç–∞ {i}",
                        "description": f"–û–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä—Ç—ã {i}",
                        "mechanics": {"type": "test", "value": i}
                    }
                ],
                "subraces": {}
            }

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–Ω–æ–≥–æ —è–∑—ã–∫–æ–≤
        for i in range(20):
            lang_id = f"lang_{i}"
            large_languages_data["languages"][lang_id] = {
                "code": lang_id,
                "type": "standard",
                "difficulty": "easy",
                "localization_keys": {},
                "mechanics": {"learnable_by_all": i % 5 == 0},
                "fallback_data": {"name": f"Language {i}"}
            }

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as races_file:
            yaml.dump(large_races_data, races_file)
            races_file.flush()

            with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as languages_file:
                yaml.dump(large_languages_data, languages_file)
                languages_file.flush()

                try:
                    import time

                    # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞—Å
                    start_time = time.time()
                    race_loader = RaceLoader(Path(races_file.name))
                    races = race_loader.load_races()
                    races_time = time.time() - start_time

                    # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ —è–∑—ã–∫–æ–≤
                    start_time = time.time()
                    language_service = LanguageService(Path(languages_file.name))
                    languages = language_service.get_all_languages()
                    languages_time = time.time() - start_time

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    assert len(races) == 100
                    assert len(languages) == 20

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—ã—Å—Ç—Ä–æ)
                    assert races_time < 1.0, f"Loading races took too long: {races_time}s"
                    assert languages_time < 0.5, f"Loading languages took too long: {languages_time}s"

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç—É —Å –±–æ–ª—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    for _race_id, race in races.items():
                        assert race.name.startswith("–†–∞—Å–∞ ")
                        assert len(race.features) == 1

                    for _lang_id, language in languages.items():
                        assert language.code.startswith("lang_")

                finally:
                    # –û—á–∏—Å—Ç–∫–∞
                    Path(races_file.name).unlink()
                    Path(languages_file.name).unlink()


@pytest.mark.integration
@pytest.mark.regression
class TestRegressionIntegration:
    """–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã."""

    def test_yaml_loading_consistency(self) -> None:
        """–¢–µ—Å—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ YAML."""
        test_data = {
            "races": {
                "test_race": {
                    "name": "–¢–µ—Å—Ç–æ–≤–∞—è —Ä–∞—Å–∞",
                    "description": "–¢–µ—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ",
                    "ability_bonuses": {"strength": 2},
                    "size": "medium",
                    "speed": 30,
                    "languages": ["common"],
                    "features": [],
                    "subraces": {}
                }
            }
        }

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as f:
            yaml.dump(test_data, f)
            f.flush()

            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑
                loader1 = RaceLoader(Path(f.name))
                loader2 = RaceLoader(Path(f.name))

                races1 = loader1.load_races()
                races2 = loader2.load_races()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
                assert len(races1) == len(races2) == 1

                race1 = races1["test_race"]
                race2 = races2["test_race"]

                assert race1.name == race2.name
                assert race1.description == race2.description
                assert race1.ability_bonuses == race2.ability_bonuses
                assert race1.size == race2.size
                assert race1.speed == race2.speed
                assert race1.languages == race2.languages

            finally:
                Path(f.name).unlink()

    def test_language_service_state_isolation(self) -> None:
        """–¢–µ—Å—Ç –∏–∑–æ–ª—è—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è LanguageService."""
        test_data1 = {
            "language_metadata": {"types": {}, "difficulties": {}},
            "languages": {
                "lang1": {
                    "code": "lang1",
                    "type": "standard",
                    "difficulty": "easy",
                    "localization_keys": {},
                    "mechanics": {},
                    "fallback_data": {"name": "Language 1"}
                }
            }
        }

        test_data2 = {
            "language_metadata": {"types": {}, "difficulties": {}},
            "languages": {
                "lang2": {
                    "code": "lang2",
                    "type": "exotic",
                    "difficulty": "hard",
                    "localization_keys": {},
                    "mechanics": {},
                    "fallback_data": {"name": "Language 2"}
                }
            }
        }

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as f1:
            yaml.dump(test_data1, f1)
            f1.flush()

            with NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as f2:
                yaml.dump(test_data2, f2)
                f2.flush()

                try:
                    # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞
                    service1 = LanguageService(Path(f1.name))
                    service2 = LanguageService(Path(f2.name))

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–æ–ª—è—Ü–∏—é
                    languages1 = service1.get_all_languages()
                    languages2 = service2.get_all_languages()

                    assert len(languages1) == 1
                    assert len(languages2) == 1
                    assert "lang1" in languages1
                    assert "lang2" in languages2
                    assert "lang2" not in languages1
                    assert "lang1" not in languages2

                finally:
                    Path(f1.name).unlink()
                    Path(f2.name).unlink()
